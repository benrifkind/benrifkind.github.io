<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
<title type="text">This is a website</title>
<generator uri="https://github.com/jekyll/jekyll">Jekyll</generator>
<link rel="self" type="application/atom+xml" href="http://benrifkind.github.io/feed.xml" />
<link rel="alternate" type="text/html" href="http://benrifkind.github.io" />
<updated>2014-12-04T21:24:54-05:00</updated>
<id>http://benrifkind.github.io/</id>
<author>
  <name>Ben Rifkind</name>
  <uri>http://benrifkind.github.io/</uri>
  
</author>


  

<entry>
  <title type="html"><![CDATA[Mapping Stats Canada Data with R part 1 of 3]]></title>
  <link rel="alternate" type="text/html" href="http://benrifkind.github.io/Mapping-Stats-Canada-Data-with-R-part-1-of-3/" />
  <id>http://benrifkind.github.io/Mapping-Stats-Canada-Data-with-R-part-1-of-3</id>
  <published>2014-11-01T00:00:00-04:00</published>
  <updated>2014-11-01T00:00:00-04:00</updated>
  <author>
    <name>Ben Rifkind</name>
    <uri>http://benrifkind.github.io</uri>
    
  </author>
  <content type="html">&lt;h1 id=&quot;introduction&quot;&gt;Introduction&lt;/h1&gt;
&lt;p&gt;I applied to the &lt;a href=&quot;http://insightdatascience.com/&quot;&gt;Insight data science program&lt;/a&gt; pretty much immediately after I finished my phD in September. I didn’t have much programming experience (still don’t) but I was learning R and wanted to do something to showcase what I had learnt. I settled on doing a map of the densities of the different ethnic groups in Canada by census division. I just thought it would be interesting to see where different immigrant communities settle. &lt;/p&gt;

&lt;p&gt;There were three basic parts to this project. &lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;Get the data from Stats Canada. This was not one simple download. I used &lt;a href=&quot;http://www.crummy.com/software/BeautifulSoup/&quot;&gt;BeautifulSoup&lt;/a&gt; to scrape the Stats Canada web site.&lt;/li&gt;
  &lt;li&gt;Organize and combine the data along with the actual mapping. This was some simple R code along with learning a little bit of &lt;a href=&quot;http://cran.r-project.org/web/packages/ggmap/ggmap.pdf&quot;&gt;ggmaps&lt;/a&gt;&lt;/li&gt;
  &lt;li&gt;Construct an interactive map online. I used the &lt;a href=&quot;http://shiny.rstudio.com/&quot;&gt;Shiny&lt;/a&gt; web application framework for R for this.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Three different parts to that project add up to three different parts to this post.&lt;/p&gt;

&lt;h1 id=&quot;part-1---web-scraping-stats-canada&quot;&gt;Part 1 - Web Scraping Stats Canada&lt;/h1&gt;

&lt;p&gt;I went to &lt;a href=&quot;http://www.statcan.gc.ca/start-debut-eng.html&quot;&gt;the Stats Canada web site&lt;/a&gt; to look for this data. Unfortunately the long form census was discontinued in 2011, so I had to rely on the 2006 census. I focused on the ethnic characteristics of the questionnaire. This is a &lt;a href=&quot;http://www12.statcan.gc.ca/census-recensement/2006/dp-pd/tbt/Rp-eng.cfm?LANG=E&amp;amp;APATH=3&amp;amp;DETAIL=0&amp;amp;DIM=0&amp;amp;FL=A&amp;amp;FREE=0&amp;amp;GC=0&amp;amp;GID=0&amp;amp;GK=0&amp;amp;GRP=1&amp;amp;PID=99015&amp;amp;PRID=0&amp;amp;PTYPE=88971,97154&amp;amp;S=0&amp;amp;SHOWALL=0&amp;amp;SUB=0&amp;amp;Temporal=2006&amp;amp;THEME=70&amp;amp;VID=0&amp;amp;VNAMEE=&amp;amp;VNAMEF=&quot;&gt;link&lt;/a&gt; to the stats that I was looking at aggregated over all of Canada. I wanted the data for each census division which for some reason Stats Canada did not make available as one single download. I would have had to click through each division &lt;a href=&quot;http://www12.statcan.gc.ca/census-recensement/2006/dp-pd/tbt/Geo-index-eng.cfm?TABID=5&amp;amp;LANG=E&amp;amp;APATH=3&amp;amp;DETAIL=0&amp;amp;DIM=0&amp;amp;FL=A&amp;amp;FREE=0&amp;amp;GC=0&amp;amp;GID=0&amp;amp;GK=0&amp;amp;GRP=1&amp;amp;PID=99015&amp;amp;PRID=0&amp;amp;PTYPE=88971,97154&amp;amp;S=0&amp;amp;SHOWALL=0&amp;amp;SUB=0&amp;amp;Temporal=2006&amp;amp;THEME=70&amp;amp;VID=0&amp;amp;VNAMEE=&amp;amp;VNAMEF=&amp;amp;D1=0&amp;amp;D2=0&amp;amp;D3=0&amp;amp;D4=0&amp;amp;D5=0&amp;amp;D6=0&quot;&gt;here&lt;/a&gt; in order to retrieve all the data. So of course what I did instead was I scraped the data from that page using python, regular expressions, and BeautifulSoup.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;urllib&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;bs4&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SoupStrainer&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;re&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;os&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I started at the &lt;a href=&quot;http://www12.statcan.gc.ca/census-recensement/2006/dp-pd/tbt/Geo-index-eng.cfm?TABID=5&amp;amp;LANG=E&amp;amp;APATH=3&amp;amp;DETAIL=0&amp;amp;DIM=0&amp;amp;FL=A&amp;amp;FREE=0&amp;amp;GC=0&amp;amp;GID=0&amp;amp;GK=0&amp;amp;GRP=1&amp;amp;PID=99015&amp;amp;PRID=0&amp;amp;PTYPE=88971,97154&amp;amp;S=0&amp;amp;SHOWALL=0&amp;amp;SUB=0&amp;amp;Temporal=2006&amp;amp;THEME=70&amp;amp;VID=0&amp;amp;VNAMEE=&amp;amp;VNAMEF=&amp;amp;D1=0&amp;amp;D2=0&amp;amp;D3=0&amp;amp;D4=0&amp;amp;D5=0&amp;amp;D6=0&quot;&gt;base page&lt;/a&gt; and took a look at the html code to see what all the census division links had in common. All the links had tags ‘li’. The provinces were of class ‘indent-1’, the census divisions were of class, “indent-3”, and the subdivisions were of class ‘indent-5’. And the links are listed in inherited order - provinces -&amp;gt; divisions -&amp;gt; subdivisions. I’m interested in the census divisions along with the provinces (just as placeholders). &lt;/p&gt;

&lt;p&gt;I found parsing the page a bit buggy. I had to use the “html5lib” parser to get all the links.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;c&quot;&gt;#the base page&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;http://www12.statcan.gc.ca/census-recensement/2006/dp-pd/tbt/Geo-index-eng.cfm?TABID=5&amp;amp;LANG=E&amp;amp;APATH=3&amp;amp;DETAIL=0&amp;amp;DIM=0&amp;amp;FL=A&amp;amp;FREE=0&amp;amp;GC=0&amp;amp;GID=0&amp;amp;GK=0&amp;amp;GRP=1&amp;amp;PID=99015&amp;amp;PRID=0&amp;amp;PTYPE=88971,97154&amp;amp;S=0&amp;amp;SHOWALL=0&amp;amp;SUB=0&amp;amp;Temporal=2006&amp;amp;THEME=70&amp;amp;VID=0&amp;amp;VNAMEE=&amp;amp;VNAMEF=&amp;amp;D1=0&amp;amp;D2=0&amp;amp;D3=0&amp;amp;D4=0&amp;amp;D5=0&amp;amp;D6=0&amp;quot;&lt;/span&gt;

&lt;span class=&quot;c&quot;&gt;#get the links&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BeautifulSoup&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;requests&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;url&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;content&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;html5lib&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;links&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;soup&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find_all&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;li&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;class_&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;compile&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;indent-[1|3]&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I still wasn’t there yet. These links just take me to another page where I have the option to click on a link to download the csv files. But I noticed that these new links are of the form begin + PID + “&amp;amp;”” + GID +end, where begin and end are some fixed string and PID and GID are information contained in the link. So I wrote a function to extract the link to download the csv files from the first link.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_csv_link&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weblink&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#extract the pid and gid from the link&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;PID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;PID=\d+&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weblink&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;GID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;search&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;GID=\d+&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weblink&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;group&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;#construct link to the csv file&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;http://www12.statcan.gc.ca/census-recensement/2006/dp-pd/tbt/File.cfm?S=0&amp;amp;LANG=E&amp;amp;A=R&amp;amp;&amp;quot;&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;&amp;amp;D1=0&amp;amp;D2=0&amp;amp;D3=0&amp;amp;D4=0&amp;amp;D5=0&amp;amp;D6=0&amp;amp;OFT=CSV&amp;quot;&lt;/span&gt;   
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;begin&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;amp;&amp;#39;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;GID&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;end&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now I just retrieve a dictionary of dictionaries of urls. First level is the name of the province, second level is name of the census division and the final level is url of the csv for that division. This structure helps keep things organized.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;n&quot;&gt;list_divs&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;province&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;#39;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;link&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;links&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:]:&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#skip first link Canada &lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;link&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;class&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;indent-1&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;province&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot; /.+&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;link&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;c&quot;&gt;#removes french name and /&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;link&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;class&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;indent-3&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;province&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;!=&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;list_divs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;province&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;re&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;sub&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot; /.+&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;link&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;string&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; 
                &lt;span class=&quot;n&quot;&gt;get_csv_link&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;link&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The last thing to do is to take this structure and use it to download the csv files into the right folders. For each province I make a folder and put all the census division files of that province in that folder.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;province&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;list_divs&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;os&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;mkdir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;province&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;division&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;province&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]:&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;urllib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;urlretrieve&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;list_divs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;province&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;][&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;division&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;province&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;/&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;division&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;.csv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Next up: cleaning and combing the csv files to get data I can map&lt;/p&gt;


  &lt;p&gt;&lt;a href=&quot;http://benrifkind.github.io/Mapping-Stats-Canada-Data-with-R-part-1-of-3/&quot;&gt;Mapping Stats Canada Data with R part 1 of 3&lt;/a&gt; was originally published by Ben Rifkind at &lt;a href=&quot;http://benrifkind.github.io&quot;&gt;This is a website&lt;/a&gt; on November 01, 2014.&lt;/p&gt;</content>
</entry>


  

<entry>
  <title type="html"><![CDATA[Analysis of Bicep Curl Quality]]></title>
  <link rel="alternate" type="text/html" href="http://benrifkind.github.io/Analysis-of-Bicep-Curl-Quality/" />
  <id>http://benrifkind.github.io/Analysis-of-Bicep-Curl-Quality</id>
  <published>2014-10-30T00:00:00-04:00</published>
  <updated>2014-10-30T00:00:00-04:00</updated>
  <author>
    <name>Ben Rifkind</name>
    <uri>http://benrifkind.github.io</uri>
    
  </author>
  <content type="html">&lt;p&gt;For my first post I thought I’d write about some basic data classification. I’ve been going through the courses given by Carnegie Melon in the &lt;a href=&quot;https://www.coursera.org/specialization/jhudatascience/1&quot;&gt;Data Science Specialization Stream&lt;/a&gt; to learn R and some 
introductory data science techniques. I recommend it. &lt;/p&gt;

&lt;p&gt;Anyway, for the &lt;a href=&quot;https://class.coursera.org/predmachlearn-006&quot;&gt;Practical Machine Learning Course&lt;/a&gt; they asked us to classify the how well people were performing bicep curls. The data as well as the explanation of the problem is &lt;a href=&quot;http://groupware.les.inf.puc-rio.br/har&quot;&gt;here&lt;/a&gt;. We have data taken from subjects wearing sensors while they perform a bicep curl with five differing techniques (“A”, “B”, “C”, “D”, “E”). “A” corresponds to a “proper” bicep curl and the rest are differing bad techniques. The goal is to use this data to construct a classifier that can then predict the type of bicep curl using only the sensory data.   &lt;/p&gt;

&lt;p&gt;The &lt;a href=&quot;http://cran.r-project.org/web/packages/randomForest/index.html&quot;&gt;random forest&lt;/a&gt; worked extremely well for this. &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;randomForest&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;ggplot2&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;kn&quot;&gt;library&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;caret&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Read in the training data&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;train &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; read.csv&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;pml-training.csv&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; stringsAsFactors &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;There were a lot of columns which had many NA values and/or just missing data. I wrote a function to find the indices of these ‘useless’ columns. From inspecting the columns it seemed appropriate to remove those which did not have more than 406 entries which are not blank or NA.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;#function to find index of columns with very little usable data&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#from training data (blanks and NA&amp;#39;s)&lt;/span&gt;
bad.cols &lt;span class=&quot;o&quot;&gt;&amp;lt;-&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dataframe&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; threshold &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;406&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;#count how many non NA&amp;#39;s are in a column&lt;/span&gt;
  count.non.nas &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;kp&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;is.na&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt; 
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;#find columns with too many na&amp;#39;s&lt;/span&gt;
  na.cols &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dataframe&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; MARGIN &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; count.non.nas&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; threshold
  na.cols &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;which&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;na.cols &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
  &lt;span class=&quot;c1&quot;&gt;#count how many columns do not have blanks&lt;/span&gt;
  count.non.blanks &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kr&quot;&gt;function&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;){&lt;/span&gt;
    &lt;span class=&quot;kp&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;nchar&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;x&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
  &lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
  &lt;span class=&quot;c1&quot;&gt;#remove columns with too many blanks&lt;/span&gt;
  blank.cols &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;dataframe&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; MARGIN &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; count.non.blanks&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; threshold
  blank.cols &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;which&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;blank.cols &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;F&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  
  &lt;span class=&quot;kr&quot;&gt;return&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;unique&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;na.cols&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; blank.cols&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;The indices of the unnecessary columns are &lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;no.use.col &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; bad.cols&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;train&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
no.use.col &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;7&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; no.use.col&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
no.use.col&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;##   [1]   1   2   3   4   5   6   7  18  19  21  22  24  25  27  28  29  30
##  [18]  31  32  33  34  35  36  50  51  52  53  54  55  56  57  58  59  75
##  [35]  76  77  78  79  80  81  82  83  93  94  96  97  99 100 103 104 105
##  [52] 106 107 108 109 110 111 112 131 132 134 135 137 138 141 142 143 144
##  [69] 145 146 147 148 149 150  12  13  14  15  16  17  20  23  26  69  70
##  [86]  71  72  73  74  87  88  89  90  91  92  95  98 101 125 126 127 128
## [103] 129 130 133 136 139&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Now I prepare the data by separating out the classification column and removing the unnecessary columns. Since the classification column will not be used for analysis I remove it and keep track of it for later.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;train.class &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;as.factor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;train&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;classe&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

train &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; train&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;no.use.col&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
train&lt;span class=&quot;o&quot;&gt;$&lt;/span&gt;classe &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;NULL&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;I am
using PCA to reduce dimensionality. First have to center and rescale the data. The centering and scaling comes from the training data.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;&lt;span class=&quot;c1&quot;&gt;#calculate mean and standard deviations for each column of train&lt;/span&gt;
means &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;colMeans&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;train&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
sds &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;apply&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;train&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; sd&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#center and rescale&lt;/span&gt;
train &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;as.data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;train&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt; means&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;sds&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#do PCA&lt;/span&gt;
train.prcomp &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; prcomp&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;train&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; center &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;FALSE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#predict using PCA&lt;/span&gt;
train &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;as.data.frame&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;predict&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;train.prcomp&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; newdata &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; train&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;A plot of the first two principal components of the training set. Do they separate 
the data well? I don’t really see good separation…&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;qplot&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;PC1&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; PC2&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; data &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; train&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; colour &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; train.class&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;/../figs/2014-10-30-Fit-Analysis/unnamed-chunk-7-1.png&quot; alt=&quot;center&quot; /&gt; &lt;/p&gt;

&lt;p&gt;Now use the random forest to predict. I split the data into train (80%) and validation (20%) pieces. I ran random forest on the train set, used the model to predict on the validation set and calculated the error between the predicted and actual values.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;train.cut &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; train&lt;span class=&quot;p&quot;&gt;[,&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;c&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;25&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt; &lt;span class=&quot;c1&quot;&gt;#use only a few of PCA&amp;#39;s&lt;/span&gt;

&lt;span class=&quot;kp&quot;&gt;set.seed&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1224&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#split the data&lt;/span&gt;
index &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;sample&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;train.cut&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; size &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;0.8&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;*&lt;/span&gt;&lt;span class=&quot;kp&quot;&gt;nrow&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;train.cut&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
X &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; train.cut&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;index&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
validation &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; train.cut&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;index&lt;span class=&quot;p&quot;&gt;,]&lt;/span&gt;

&lt;span class=&quot;c1&quot;&gt;#fit the model&lt;/span&gt;
fit &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; randomForest&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;X&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; train.class&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;index&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt;
               importance &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;TRUE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; ntree &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;m&quot;&gt;130&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
predictions &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; predict&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;fit&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; newdata &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; validation&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Table of predictions on validation set against actual values and calculated cross-tabulation of observed and predicted classed.&lt;/p&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-r&quot; data-lang=&quot;r&quot;&gt;predict.table &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kp&quot;&gt;table&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;predict &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; predictions&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; true &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; train.class&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;index&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
confusionMatrix&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;predict.table&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;

&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;## Confusion Matrix and Statistics
## 
##        true
## predict    A    B    C    D    E
##       A 1128   13    2    0    0
##       B    3  750    9    0    2
##       C    3    6  676   27    9
##       D    0    1    7  591    4
##       E    0    1    3    4  686
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9761          
##                  95% CI : (0.9708, 0.9806)
##     No Information Rate : 0.2889          
##     P-Value [Acc &amp;gt; NIR] : &amp;lt; 2.2e-16       
##                                           
##                   Kappa : 0.9696          
##  Mcnemar&amp;#39;s Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9947   0.9728   0.9699   0.9502   0.9786
## Specificity            0.9946   0.9956   0.9861   0.9964   0.9975
## Pos Pred Value         0.9869   0.9817   0.9376   0.9801   0.9885
## Neg Pred Value         0.9978   0.9934   0.9934   0.9907   0.9954
## Prevalence             0.2889   0.1964   0.1776   0.1585   0.1786
## Detection Rate         0.2874   0.1911   0.1722   0.1506   0.1748
## Detection Prevalence   0.2912   0.1946   0.1837   0.1536   0.1768
## Balanced Accuracy      0.9947   0.9842   0.9780   0.9733   0.9881&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;


  &lt;p&gt;&lt;a href=&quot;http://benrifkind.github.io/Analysis-of-Bicep-Curl-Quality/&quot;&gt;Analysis of Bicep Curl Quality&lt;/a&gt; was originally published by Ben Rifkind at &lt;a href=&quot;http://benrifkind.github.io&quot;&gt;This is a website&lt;/a&gt; on October 30, 2014.&lt;/p&gt;</content>
</entry>

</feed>
